import glob
import pandas as pd
import snakemake.utils

# this is the number of seed genes to run the pipeline
test_seeds=500
# PARAMS
# minimum length of seed protein to keep
min_len = 0

# target per queries in both foldseek and blast
target_seqs=1000
max_seqs_brh = 5

# blast evalue
eval_both = 1e-3
eval_brh = 10


# how many sequence max to do the tree?
max_seqs = 150

# min lddt to mask residues
min_lddt = 50
# Ultrafast bootstrap for iqtree
UF_boot = 1000

# trimal parameters
# trimal_cons = 30
# trimal_gt = 0.1
# if trimmed aln shorter than this exclude
# min_trim_len = 30

# type of diff matrixed for foldtree
# mattypes = ['fident', 'alntmscore', 'lddt']
modes = ['blast', 'fs', 'common']
methods = ['blast', 'fs']
alphabets = ['aa', '3Di']
alphabets_fident = ['aa', '3Di', 'fident']


# files and folders
subst_matrix = "data/subst_matrixes/mat3di.out"
sequence_dir = 'data/fastas/'
structure_dir = 'data/structures/'
outdir = 'results/'

dataset=config['name_dataset']
input_table = pd.read_csv(config['input_table_file'], header=None, sep='\t')
input_table.columns = ['uniprot', 'taxid', 'count1', 'count2', 'count3', 'genome', 'source', 'species', 'mnemo']
input_dict = input_table.set_index('uniprot').T.to_dict()

codes = list(input_table['uniprot'])

seed_sps=config['seed']

# possible combinations:
combinations_codes_str=[x+"_"+y for x in codes for y in codes]

rule all:
    input:
        outdir+dataset+'/db/db_num.tsv',
        expand(sequence_dir+'{code}.fa', code=codes),
        # expand(outdir+dataset+"/homology/allvall/{comb}_{method}.tsv", comb=combinations_codes_str, method=methods),
        expand(outdir+dataset+"/homology/{seed}_{method}_brh.tsv", seed=seed_sps, method=methods),
        expand(outdir+dataset+"/plots/{seed}_homology.png", seed=seed_sps),
        expand(outdir+dataset+"/plots/{seed}_saturation.png", seed=seed_sps),
        expand(outdir+dataset+"/trees/{seed}_{root}_trees.txt", seed=seed_sps, root=["rooted", "unrooted"]),
        # expand(outdir+dataset+"/trees/{seed}_{mode}_ft.txt", seed=seed_sps, mode=modes),
        # expand(outdir+dataset+"/plots/"+dataset+"_{seed}_trees.png", seed=seed_sps),
        expand(outdir+dataset+"/reco/{seed}_scores.tsv", seed=seed_sps),
        expand(outdir+dataset+"/reco/{seed}_{mode}_{alphabet}_apro.nwk", seed=seed_sps, mode=modes, alphabet=alphabets_fident),
        expand(outdir+dataset+"/plots/{seed}_runtime.pdf", seed=seed_sps),
        expand(outdir+dataset+"/plots/{seed}_astral_pro.pdf", seed=seed_sps),
        expand(outdir+dataset+"/plots/{seed}_trees.pdf", seed=seed_sps),


rule get_nums:
    input: config['input_table_file']
    output: outdir+dataset+'/db/db_num.tsv'
    shell:'''
echo -e "id\\tseqs\\tstruct\\tdiff" > {output}
for id in $(cut -f1 {input}); do
    seqs=$(wc -l < data/ids/${{id}}.txt)
    struct=$(find data/structures/$id/high_cif -name "*cif.gz" | wc -l)
    echo -e "$id\\t$seqs\\t$struct" | awk '{{print $0"\\t"$2-$3}}'
done >> {output}
'''

rule make_fastas:
    input: structure_dir+'{code}/high_cif'
    output: sequence_dir+'{code}.fa'
    threads: 8
    shell:'''
python ./scripts/cif2fasta.py -i {input} -o {output} -c {threads} -l {min_len}
'''

rule make_taxidmap:
    input: rules.make_fastas.output
    output: temp(outdir+dataset+'/db/{code}.taxid')
    params:
        taxid=lambda wcs: str(input_dict[wcs.code]['taxid'])
    shell:'''
grep ">" {input} | sed 's/>//' | awk '{{print $0"\\t"{params.taxid}}}' > {output}
'''

rule make_blastdb:
    input:
        fa=expand(sequence_dir+'{code}.fa', code=codes),
        maps=expand(outdir+dataset+'/db/{code}.taxid', code=codes)
    output:
        fa=outdir+dataset+"/db/all_seqs.fa",
        blast=outdir+dataset+"/db/all_seqs_blastdb.pdb",
        mapid=outdir+dataset+"/db/taxidmap"
    shell:'''
cat {input.maps} > {output.mapid}
cat {input.fa} > {output.fa}
out_file=$(echo {output.blast} | rev | cut -f 2- -d '.' | rev)
makeblastdb -in {output.fa} -out $out_file -parse_seqids -taxid_map {output.mapid} -dbtype prot
'''

rule make_foldseekdb:
    input:
        all_struct=expand(structure_dir+'{code}/high_cif', code=codes),
    output:
        outdir+dataset+"/db/all_seqs_fsdb"
    shell:'''
structsdir=$(dirname {output})/structs
mkdir -p $structsdir

for id in {input}; do
bn=$(dirname $id | rev | cut -f1 -d'/' | rev)

if [ -L $structsdir/$bn ]; then
    unlink $structsdir/$bn
fi
ln -s -f -r $id $structsdir/$bn
done

foldseek createdb $structsdir {output}
'''

rule make_foldseekdb_seq:
    input: rules.make_foldseekdb.output
    output: outdir+dataset+"/db/all_seqs_fsdb_ss.fa"
    shell:'''
foldseek lndb {input}_h {input}_ss_h
foldseek convert2fasta {input}_ss {output}
sed -i 's/-model_v4.cif.gz//g' {output}
'''

rule make_blastdb_single:
    input:
        fa=rules.make_fastas.output,
        mapid=rules.make_blastdb.output.mapid
    output:
        outdir+dataset+"/db/single_dbs/{code}.pdb"
    shell:'''
out_file=$(echo {output} | rev | cut -f 2- -d '.' | rev)
makeblastdb -in {input.fa} -out $out_file -parse_seqids -taxid_map {input.mapid} -dbtype prot
'''

rule make_foldseekdb_single:
    input: structure_dir+'{code}/high_cif',
    output: outdir+dataset+"/db/single_dbs/{code}_fsdb"
    threads:
        8
    shell:'''
foldseek createdb --threads {threads} {input} {output}
'''

rule blast:
    input:
        q=sequence_dir+'{seed}.fa',
        db=rules.make_blastdb.output.blast,
    output: outdir+dataset+"/homology/{seed}_blast.tsv"
    benchmark: outdir+dataset+"/benchmarks/homology/{seed}_blast.txt"
    threads:
        24
    shell:'''
dbfile=$(echo {input.db} | rev | cut -f 2- -d '.' | rev)
blastp -query {input.q} -db $dbfile -out {output} -max_hsps 1 -max_target_seqs {target_seqs} \
-outfmt "6 std qcovs qcovhsp qlen slen staxids" -num_threads {threads}
'''

rule foldseek:
    input:
        q=structure_dir+'{seed}/high_cif',
        db=rules.make_foldseekdb.output
    output: 
        outdir+dataset+"/homology/{seed}_fs.tsv"
    log: outdir+dataset+"/log/homology/{seed}_fs.log"
    benchmark: outdir+dataset+"/benchmarks/homology/{seed}_fs.txt"
    threads:
        24
    shell:'''
foldseek easy-search {input.q} {input.db} {output} $TMPDIR/{wildcards.seed} --threads {threads} --max-seqs {target_seqs} \
--format-output query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,lddt,alntmscore,rmsd,prob,qcov,tcov > {log}
sed -i 's/-model_v4.cif.gz//g' {output}
'''

rule blast_allvall:
    input:
        q=sequence_dir+'{seed}.fa',
        t=sequence_dir+'{code}.fa',
        q_db=outdir+dataset+"/db/single_dbs/{seed}.pdb",
        t_db=outdir+dataset+"/db/single_dbs/{code}.pdb",
    output: 
        q_t=outdir+dataset+"/homology/allvall/{seed}_{code}_blast.tsv",
        t_q=outdir+dataset+"/homology/allvall/{code}_{seed}_blast.tsv"
    benchmark: outdir+dataset+"/benchmarks/homology/{code}_{seed}_blast.txt"
    threads:
        4
    shell:'''
dbfile1=$(echo {input.t_db} | rev | cut -f 2- -d '.' | rev)
blastp -query {input.q} -db $dbfile1 -out {output.q_t} \
-outfmt "6 std qcovs qcovhsp qlen slen staxids" -num_threads {threads} -max_hsps 1 -max_target_seqs {max_seqs_brh}

dbfile2=$(echo {input.q_db} | rev | cut -f 2- -d '.' | rev)
blastp -query {input.t} -db $dbfile2 -out {output.t_q} \
-outfmt "6 std qcovs qcovhsp qlen slen staxids" -num_threads {threads} -max_hsps 1 -max_target_seqs {max_seqs_brh}
'''

rule foldseek_allvall:
    input:
        q=structure_dir+'{seed}/high_cif',
        t=structure_dir+'{code}/high_cif'
    output:
        q_t=outdir+dataset+"/homology/allvall/{seed}_{code}_fs.tsv",
        t_q=outdir+dataset+"/homology/allvall/{code}_{seed}_fs.tsv"
    log: outdir+dataset+"/log/homology/{code}_{seed}_fs.log"
    benchmark: outdir+dataset+"/benchmarks/homology/{code}_{seed}_fs.txt"
    threads:
        4
    shell:'''
foldseek easy-search {input.q} {input.t} {output.q_t} $TMPDIR/{wildcards.seed}_{wildcards.code} \
--threads {threads} --max-seqs {max_seqs_brh} \
--format-output query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,lddt,alntmscore,rmsd,prob,qcov,tcov > {log}
sed -i 's/-model_v4.cif.gz//g' {output.q_t}

foldseek easy-search {input.t} {input.q} {output.t_q} $TMPDIR/{wildcards.code}_{wildcards.seed} \
--threads {threads} --max-seqs {max_seqs_brh} \
--format-output query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,lddt,alntmscore,rmsd,prob,qcov,tcov > {log}
sed -i 's/-model_v4.cif.gz//g' {output.t_q}
'''

rule blast_brh:
    input: 
        a=expand(outdir+dataset+"/homology/allvall/{seed}_{code}_blast.tsv", seed=seed_sps, code=codes),
        b=expand(outdir+dataset+"/homology/allvall/{code}_{seed}_blast.tsv", seed=seed_sps, code=codes)
    output:
        outdir+dataset+"/homology/{seed}_blast_brh.tsv"
    shell:'''
python scripts/get_BRH.py -h1 {input.a} -h2 {input.b} -o {output} -e {eval_brh}
'''

rule foldseek_brh:
    input: 
        a=expand(outdir+dataset+"/homology/allvall/{seed}_{code}_fs.tsv", seed=seed_sps, code=codes),
        b=expand(outdir+dataset+"/homology/allvall/{code}_{seed}_fs.tsv", seed=seed_sps, code=codes)
    output:
        outdir+dataset+"/homology/{seed}_fs_brh.tsv"
    shell:'''
python scripts/get_BRH.py -h1 {input.a} -h2 {input.b} -o {output} -e {eval_brh}
'''


rule plot_evalues:
    input:
        table=config['input_table_file'],
        groups=config['taxons_file'],
        taxidmap=rules.make_blastdb.output.mapid,
        blast=rules.blast.output,
        blast_brh=rules.blast_brh.output,
        self_blast=outdir+dataset+"/homology/allvall/{seed}_{seed}_blast.tsv",
        fs=rules.foldseek.output,
        fs_brh=rules.foldseek_brh.output,
        self_fs=outdir+dataset+"/homology/allvall/{seed}_{seed}_fs.tsv"
    output: 
        eda=outdir+dataset+"/plots/{seed}_homology.png",
        saturation=outdir+dataset+"/plots/{seed}_saturation.png"
    shell:'''
Rscript scripts/compare_sampling.R -i {input.table} -m {input.groups} -t {input.taxidmap} \
-b {input.blast} -f {input.fs} --bb {input.blast_brh} --fb {input.fs_brh} \
--sb {input.self_blast} --sf {input.self_fs} -o {output.eda} --o2 {output.saturation} -e {eval_both} -s {max_seqs}
'''


# first checkpoint and get the uniq ids in the blast or foldseek result
checkpoint geneids_todo:
    input:
        blast=rules.blast.output,
        fs=rules.foldseek.output
    output:
        blast=outdir+dataset+"/ids/{seed}_blast.ids",
        fs=outdir+dataset+"/ids/{seed}_fs.ids",
        common=outdir+dataset+"/ids/{seed}_common.ids"
    shell:'''
cut -f1 {input.blast} | sort -u | sort > {output.blast}
cut -f1 {input.fs} | sort -u | sort > {output.fs}
comm -12 {output.blast} {output.fs} | shuf -n {test_seeds} > {output.common}
'''

####### TREE PIPELINE ########

##### HOMOLOGY FILTERING #####

# get the targets ids and the subset homology table for fs and blast 
rule get_ids:
    input: outdir+dataset+"/homology/{seed}_{method}.tsv"
    output: 
        txt=outdir+dataset+"/seeds/{seed}/{i}/{i}.{method}",
        ids=outdir+dataset+"/seeds/{seed}/{i}/{i}_{method}.ids"
    shell:'''
mkdir -p $(dirname {output.txt})
awk '$1=="AF-{wildcards.i}-F1"' {input} | awk '$11<{eval_both}' > {output.txt}
seed_gene=$(cut -f1 {output.txt} | sort -u)
echo $seed_gene > {output.ids}
n_hits=$(wc -l < {output.txt})
if [ $n_hits -gt 1 ]; then
    sort -gr -k12 {output.txt} | cut -f2 | grep -v -w $seed_gene | sort -u | awk 'NR < {max_seqs}' >> {output.ids}
fi
sort {output.ids} -o {output.ids}
'''

rule get_common_ids:
    input: 
        blast=outdir+dataset+"/seeds/{seed}/{i}/{i}_blast.ids",
        fs=outdir+dataset+"/seeds/{seed}/{i}/{i}_fs.ids"
    output: 
        outdir+dataset+"/seeds/{seed}/{i}/{i}_common.ids"
    shell:'''
comm -12 {input.blast} {input.fs} > {output}
'''

def seeds_homology(wildcards):
    checkpoint_output = checkpoints.geneids_todo.get(**wildcards).output.common
    with open(checkpoint_output) as all_genes:
        seed_genes = [gn.strip() for gn in all_genes]
        parsed_seed_genes = [gn.split('-')[1] for gn in seed_genes]
    return expand(outdir+dataset+"/seeds/{seed}/{i}/{i}_common.ids", seed=wildcards.seed, i=parsed_seed_genes, mode=modes)

checkpoint check_orphans:
    input: seeds_homology
    output:
        exclude=outdir+dataset+"/ids/{seed}_orphans.exclude",
        continue_aln=outdir+dataset+"/ids/{seed}_aln.ids",
    shell:'''
> {output.exclude}
> {output.continue_aln}

for file in {input}; do
    n_hits=$(wc -l < $file)
    if [ $n_hits -lt 4 ]; then
        echo -e "$(basename $file | cut -f1 -d'_')\tless than 4 common hits" >> {output.exclude}
    else
        echo "$(basename $file | cut -f1 -d'_')" >> {output.continue_aln}
    fi
done
'''

###### ALIGNMENT ######

rule aln_aa:
    input: 
        ids=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}.ids",
        fa=rules.make_blastdb.output.fa
    output:
        seq=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_aa.seqs",
        aln=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_aa.alg"
    log: outdir+dataset+"/log/mafft/{seed}_{i}_{mode}_aa.log"
    benchmark: outdir+dataset+"/benchmarks/mafft/{seed}_{i}_{mode}_aa.txt"
    threads:
        4
    shell:'''
seqkit grep -f {input.ids} {input.fa} > {output.seq}
mafft --auto --thread {threads} {output.seq} > {output.aln} 2> {log}
'''

# If foldseek, retrieve sequences from "translated version"
rule aln_3Di:
    input:
        ids=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}.ids",
        fa=rules.make_foldseekdb_seq.output
    output:
        seq=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_3Di.seqs",
        masked=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_3Di.masked.seqs",
        aln=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_3Di.alg"
    log: outdir+dataset+"/log/mafft/{seed}_{i}_{mode}_3Di.log"
    benchmark: outdir+dataset+"/benchmarks/mafft/{seed}_{i}_{mode}_3Di.txt"
    threads: 4
    shell:'''
seqkit grep -f {input.ids} {input.fa} > {output.seq}
python scripts/mask_structures.py -i {output.seq} -o {output.masked} -m {min_lddt} -s {structure_dir}
mafft --auto --thread {threads} --aamatrix {subst_matrix} {output.masked} > {output.aln} 2> {log}
'''

###### TRIMMING ######
rule trim_aln:
    input: outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{alphabet}.alg"
    output: outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{alphabet}.alg.clean"
    shell: '''
trimal -in {input} -out {output} -gappyout
'''
# trimal -in {input} -out {output} -cons {trimal_cons} -gt {trimal_gt}

###### ML TREE RECONSTRUCTION ######

rule iqtree:
    input: outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{alphabet}.alg.clean"
    output: 
        tree=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{alphabet}.treefile",
        treeline=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{alphabet}.treeline"
    log: outdir+dataset+"/log/iqtree/{seed}_{i}_{mode}_{alphabet}.log"
    benchmark: outdir+dataset+"/benchmarks/iqtree/{seed}_{i}_{mode}_{alphabet}.txt"
    threads: 4
    shell: '''
tree_prefix=$(echo {output.tree} | sed 's/.treefile//')

if [ {wildcards.alphabet} = "3Di" ]; then
    model="GTR20+G4"
else
    model="LG+G4"
fi

iqtree2 -s {input} --prefix $tree_prefix -B {UF_boot} -T {threads} --boot-trees --quiet -m $model --mem 4G --cmin 4 --cmax 10

best_model=$(grep "Model of substitution:" ${{tree_prefix}}.iqtree | cut -f2 -d':' | sed 's/ //')
loglik=$(grep "Log-likelihood of the tree:" ${{tree_prefix}}.iqtree | cut -f2 -d':' | cut -f2 -d' ')

echo -e "{wildcards.i}\t$best_model\t$loglik\t$(cat {output.tree})" > {output.treeline}

mv ${{tree_prefix}}.log {log}
rm -f ${{tree_prefix}}.iqtree ${{tree_prefix}}.model.gz ${{tree_prefix}}.splits.nex ${{tree_prefix}}.contree ${{tree_prefix}}.ckp.gz
'''

##### FOLDTREE #####

rule run_foldtree:
    input: outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}.ids"
    output:
        distmat=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_fident.txt",
        tree=outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_fident.treefile"
    log: outdir+dataset+"/log/ft/{seed}_{i}_{mode}.log"
    benchmark: outdir+dataset+"/benchmarks/ft/{seed}_{i}_{mode}.txt"
    shell: '''
indir=$(dirname {input})
mkdir -p $indir/structs_{wildcards.mode}

for id in $(cat {input}); do
zcat {structure_dir}/*/high_cif/${{id}}-model_v4.cif.gz > $indir/structs_{wildcards.mode}/${{id}}.cif
done

python ./software/foldtree/foldtree.py -i $indir/structs_{wildcards.mode} -o $indir/{wildcards.i}_{wildcards.mode} \
-t $TMPDIR/{wildcards.i}_{wildcards.mode}_ft -c $indir/{wildcards.i}_{wildcards.mode}_core \
--corecut --correction --kernel fident > {log}

rm -r $indir/structs_{wildcards.mode}
rm -r $TMPDIR/{wildcards.i}_{wildcards.mode}_ft
rm -r $indir/{wildcards.i}_{wildcards.mode}_core
rm $indir/{wildcards.i}_{wildcards.mode}_fident.txt_fastme_stat.txt $indir/{wildcards.i}_{wildcards.mode}_fident.txt.tmp
rm $indir/{wildcards.i}_{wildcards.mode}_allvall.tsv
rm $indir/{wildcards.i}_{wildcards.mode}_core_allvall.tsv
'''


rule root_tree:
    input: outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{algorithm}.treefile"
    output: outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{algorithm}.treefile.rooted"
    log: outdir+dataset+"/log/mad/{seed}_{i}_{mode}_{algorithm}.log"
    shell: '''
./software/mad {input} > {log}
sed -i \'2,$d\' {output}
'''

##### FINAL CHECK IF TREE WORKED #######

def seeds_unrooted_trees(wildcards):
    checkpoint_output = checkpoints.check_orphans.get(**wildcards).output.continue_aln
    with open(checkpoint_output) as all_genes:
        seed_genes = [gn.strip() for gn in all_genes]
    outfiles = expand(outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{alphabet}.treefile", seed=wildcards.seed, i=seed_genes, mode=modes, alphabet=alphabets_fident)
    return outfiles

def seeds_rooted_trees(wildcards):
    checkpoint_output = checkpoints.check_orphans.get(**wildcards).output.continue_aln
    with open(checkpoint_output) as all_genes:
        seed_genes = [gn.strip() for gn in all_genes]
    outfiles = expand(outdir+dataset+"/seeds/{seed}/{i}/{i}_{mode}_{alphabet}.treefile.rooted", seed=wildcards.seed, i=seed_genes, mode=modes, alphabet=alphabets_fident)
    return outfiles

checkpoint check_unrooted_trees:
    input: seeds_unrooted_trees
    output:
        trees=outdir+dataset+"/trees/{seed}_unrooted_trees.txt"
    shell:'''
> {output.trees}
for file in {input}; do
    id=$(basename $file ".treefile" | cut -f1 -d'_')
    targets=$(basename $file ".treefile" | cut -f2 -d'_')
    alphabet=$(basename $file ".treefile" | cut -f3 -d'_')
    echo -e "$id\t$targets\t$alphabet\t$(cat $file)" >> {output.trees}
done
'''

checkpoint check_rooted_trees:
    input: seeds_rooted_trees
    output:
        ids=outdir+dataset+"/ids/{seed}_finished.ids",
        trees=outdir+dataset+"/trees/{seed}_rooted_trees.txt"
    shell:'''
> {output.ids}
> {output.trees}
for file in {input}; do
    id=$(basename $file ".treefile.rooted" | cut -f1 -d'_')
    targets=$(basename $file ".treefile.rooted" | cut -f2 -d'_')
    alphabet=$(basename $file ".treefile.rooted" | cut -f3 -d'_')
    echo $id >> {output.ids}
    echo -e "$id\t$targets\t$alphabet\t$(cat $file)" >> {output.trees}
done
'''

### Comparisons

rule get_verticality:
    input: 
        trees=rules.check_rooted_trees.output.trees,
        table=config['input_table_file'],
        taxidmap=rules.make_blastdb.output.mapid,
        sptree=config['species_tree']
    output:
        lineage=temp(outdir+dataset+"/reco/{seed}_lineage.tsv"),
        table=outdir+dataset+"/reco/{seed}_scores.tsv"
    shell:'''
cut -f2,9 {input.table} | taxonkit reformat -I 1 | sed 's/;/,/g' > {output.lineage}
python software/foldtree/compute_scores.py --trees {input.trees} \
--tax {input.taxidmap} --sptree {input.sptree} --out {output.table} -l {output.lineage}
'''


rule plot_trees:
    input: 
        scores=rules.get_verticality.output.table,
        trees=outdir+dataset+"/trees/{seed}_unrooted_trees.txt"
    output:
        outdir+dataset+"/plots/{seed}_trees.pdf"
    shell: '''
Rscript scripts/compare_trees.R -s {input.scores} -t {input.trees} -o {output}
'''


rule plot_runstats:
    input: seeds_rooted_trees
    output:
        aln=outdir+dataset+"/stats/{seed}_aln.stats",
        time=outdir+dataset+"/stats/{seed}_runtime.stats",
        plot=outdir+dataset+"/plots/{seed}_runtime.pdf"
    shell:'''
basedir=$(dirname {input} | rev | cut -f2- -d'/' | rev | sort -u)
echo $basedir
seqkit stats $basedir/*/*alg* -a -b -T | cut -f1,4,6,12 > {output.aln}
datasetdir=$(echo $basedir | rev | cut -f3- -d'/' | rev)
echo $datasetdir

for file in $(find $datasetdir/benchmarks/ -type f -name "*txt"); do
    bn=$(basename $file ".txt")
    step=$(basename $(dirname $file))
    seed=$(echo $bn | cut -f1 -d'_')
    gene=$(echo $bn | cut -f2 -d'_')
    method=$(echo $bn | cut -f3 -d'_')
    alphabet=$(echo $bn | cut -f4 -d'_')
    echo -e "$bn\t$step\t$seed\t$gene\t$method\t$alphabet\t$(tail -1 $file)"
done > {output.time}

Rscript scripts/analyze_runtimes.R -t {output.time} -a {output.aln} -o {output.plot}
'''

rule prepare_astral_pro:
    input:
        table=config['input_table_file'],
        taxidmap=rules.make_blastdb.output.mapid
    output:
        outdir+dataset+"/reco/gene_species.map"
    shell:'''
csvtk join -H -t -f 2 -L {input.taxidmap} {input.table} | cut -f1,10 > {output}
'''

rule astral_pro:
    input:
        sptree=config['species_tree'],
        genemap=rules.prepare_astral_pro.output,
        trees=rules.check_unrooted_trees.output.trees,
    output: outdir+dataset+"/reco/{seed}_{mode}_{alphabet}_apro.nwk"
    params: config['root']
    shell:'''
reco_dir=$(dirname {output})
awk '$2=="{wildcards.mode}" && $3=="{wildcards.alphabet}"' {input.trees} | cut -f4 > $reco_dir/{wildcards.mode}_{wildcards.alphabet}_apro_input.nwk
astral-pro -c {input.sptree} -a {input.genemap} -u 2 -i $reco_dir/{wildcards.mode}_{wildcards.alphabet}_apro_input.nwk -o {output} -C --root {params}
'''

rule plot_astral_pro:
    input:
        sptree=config['species_tree_labels'],
        groups=config['taxons_file'],
        trees=expand(outdir+dataset+"/reco/{seed}_{mode}_{alphabet}_apro.nwk", seed=seed_sps, mode=modes, alphabet=alphabets_fident)
    output: outdir+dataset+"/plots/{seed}_astral_pro.pdf"
    shell:'''
reco_dir=$(dirname {input.trees} | sort -u)
Rscript scripts/analyze_apro.R -s {input.sptree} -m {input.groups} -a $reco_dir -o {output}
'''
### SMK Foldtree

# rule get_distances_foldseek:
#     input: outdir+dataset+"/seeds/{seed}/{i}/{i}_fs.ids"
#     output: outdir+dataset+"/seeds/{seed}/{i}/{i}_fs_allvall.txt"
#     log: outdir+dataset+"/log/fs/{seed}_{i}_struct_fs.log"
#     benchmark: outdir+dataset+"/benchmarks/fs/{seed}_{i}_struct_fs.txt"
#     shell:'''
# seqsdir=$(dirname {input})/seqs
# mkdir -p $seqsdir

# for id in $(cat {input}); do
# ln -s -f -r {structure_dir}/*/cif/${{id}}-model_v4.cif.gz $seqsdir
# done

# foldseek easy-search $seqsdir $seqsdir {output} $TMPDIR/{wildcards.i} \
# --format-output 'query,target,fident,lddt,alntmscore' --exhaustive-search -e inf > {log}

# rm -r $seqsdir
# '''


# rule get_distmat_foldseek:
#     input: outdir+dataset+"/seeds/{seed}/{i}/{i}_fs_allvall.txt"
#     output:
#         outdir+dataset+"/seeds/{seed}/{i}/{i}_fident.txt",
#         outdir+dataset+"/seeds/{seed}/{i}/{i}_alntmscore.txt",
#         outdir+dataset+"/seeds/{seed}/{i}/{i}_lddt.txt"
#     shell:'''
# python ./scripts/foldseek2distmat.py -i {input} -o {output}
# '''

# rule get_foldtree:
#     input: outdir+dataset+"/seeds/{seed}/{i}/{i}_{mattype}.txt",
#     output: outdir+dataset+"/seeds/{seed}/{i}/{i}_{mattype}_fs.nwk"
#     # benchmark: outdir+dataset+"/benchmarks/quicktree/{seed}_{i}_{mattype}.txt"
#     shell:'''
# quicktree -i m {input} | tr -d '\n' | sed -e '$a\\' > {output}
# '''

# MCL if gene clusters

# rule foldseek_mcl:
#     input: 
#         expand(outdir+"foldseek/out/{comb}_fs_filtered.tsv", comb=combinations_codes_str)
#     output: 
#         multiext(outdir+"mcl/foldseek", ".abc", ".tab", ".mci", ".I"+mcl_inflation_str)
#     shell:'''
#     outdir=$(echo {output} | xargs dirname  | sort -u)
#     mkdir -p $outdir

#     cat {input} | cut -f 1,2,11 > ${{outdir}}/foldseek.abc
#     mcxload -abc ${{outdir}}/foldseek.abc --stream-mirror --stream-neg-log10 \
#     -stream-tf 'ceil(200)' -o ${{outdir}}/foldseek.mci -write-tab ${{outdir}}/foldseek.tab
#     mcl ${{outdir}}/foldseek.mci -I {mcl_inflation} -odir $outdir

#     mcxdump -icl ${{outdir}}/out.foldseek.mci.I{mcl_inflation_str} -tabr ${{outdir}}/foldseek.tab -o ${{outdir}}/foldseek.I{mcl_inflation_str}
# '''
